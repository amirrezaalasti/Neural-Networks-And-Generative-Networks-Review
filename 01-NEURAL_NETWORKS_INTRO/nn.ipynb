{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network (1 hidden layer)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 3)  # Input layer (2) -> Hidden layer (3)\n",
    "        self.output = nn.Linear(3, 1)  # Hidden layer (3) -> Output layer (1)\n",
    "        self.activation = nn.ReLU()    # ReLU activation function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_out = self.activation(self.hidden(x))  # Apply activation after first layer\n",
    "        output = self.output(hidden_out)              # Compute final output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define a simple loss function (Mean Squared Error for regression)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Sample input (2D input features) and target\n",
    "x = torch.tensor([[0.5, -1.5]], dtype=torch.float32)  # Single data point with 2 features\n",
    "y_true = torch.tensor([[1.0]], dtype=torch.float32)   # Target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.1302935630083084\n",
      "Loss: 0.756389319896698\n",
      "Gradient of hidden.weight: tensor([[ 0.0753, -0.2258],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.4264, -1.2791]])\n",
      "Gradient of hidden.bias: tensor([0.1505, 0.0000, 0.8527])\n",
      "Gradient of output.weight: tensor([[-0.9181,  0.0000, -0.1490]])\n",
      "Gradient of output.bias: tensor([-1.7394])\n",
      "Updated hidden.weight: tensor([[ 0.0396, -0.5521],\n",
      "        [-0.5144,  0.1722],\n",
      "        [-0.1322, -0.2185]])\n",
      "Updated hidden.bias: tensor([-0.3728, -0.1067, -0.4744])\n",
      "Updated output.weight: tensor([[ 0.0053,  0.1361, -0.4753]])\n",
      "Updated output.bias: tensor([0.3919])\n"
     ]
    }
   ],
   "source": [
    "# **FEEDFORWARD: Compute predictions**\n",
    "y_pred = model(x)  # Forward pass\n",
    "print(\"Prediction:\", y_pred.item())\n",
    "\n",
    "# **LOSS CALCULATION: Compute error**\n",
    "loss = loss_function(y_pred, y_true)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# **BACKPROPAGATION: Compute gradients**\n",
    "optimizer.zero_grad()  # Reset gradients to zero\n",
    "loss.backward()  # Compute gradients using chain rule (automatic differentiation)\n",
    "\n",
    "# Print computed gradients\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Gradient of {name}:\", param.grad)\n",
    "\n",
    "# **UPDATE WEIGHTS: Gradient Descent step**\n",
    "optimizer.step()  # Update weights based on gradients\n",
    "\n",
    "# Print updated parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Updated {name}:\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Gradient of hidden.weight: tensor([[-0.0525,  0.1574],\n",
      "        [ 0.0150, -0.0451],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-0.1049,  0.0301,  0.0000,  0.0000])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-1.4218, -0.8808,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-1.0153])\n",
      "**********\n",
      "Epoch 1/10, Loss: 0.25771385431289673\n",
      "Updated hidden.weight: tensor([[ 0.4059, -0.5126],\n",
      "        [-0.1471, -0.4026],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4652, 0.3267, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2455,  0.0585, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.4749])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-0.0300,  0.0900],\n",
      "        [-0.0071,  0.0214],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-0.0600, -0.0143,  0.0000,  0.0000])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-0.3512, -0.2094,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-0.2444])\n",
      "**********\n",
      "Epoch 2/10, Loss: 0.01493234746158123\n",
      "Updated hidden.weight: tensor([[ 0.4089, -0.5216],\n",
      "        [-0.1464, -0.4047],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4712, 0.3281, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2806,  0.0794, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.4993])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-0.0065,  0.0194],\n",
      "        [-0.0018,  0.0055],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-0.0129, -0.0037,  0.0000,  0.0000])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-0.0672, -0.0397,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-0.0461])\n",
      "**********\n",
      "Epoch 3/10, Loss: 0.0005309787811711431\n",
      "Updated hidden.weight: tensor([[ 0.4096, -0.5236],\n",
      "        [-0.1463, -0.4053],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4725, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2874,  0.0834, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5039])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-0.0011,  0.0033],\n",
      "        [-0.0003,  0.0010],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-0.0022, -0.0006,  0.0000,  0.0000])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-0.0111, -0.0066,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-0.0076])\n",
      "**********\n",
      "Epoch 4/10, Loss: 1.4470629139395896e-05\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5239],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4727, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2885,  0.0840, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5047])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-1.7574e-04,  5.2722e-04],\n",
      "        [-5.1195e-05,  1.5358e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-0.0004, -0.0001,  0.0000,  0.0000])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-0.0018, -0.0011,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-0.0012])\n",
      "**********\n",
      "Epoch 5/10, Loss: 3.711478768764209e-07\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2886,  0.0841, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-2.8026e-05,  8.4079e-05],\n",
      "        [-8.1695e-06,  2.4509e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-5.6053e-05, -1.6339e-05,  0.0000e+00,  0.0000e+00])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-0.0003, -0.0002,  0.0000,  0.0000]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-0.0002])\n",
      "**********\n",
      "Epoch 6/10, Loss: 9.42762667932584e-09\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2887,  0.0842, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-4.4392e-06,  1.3318e-05],\n",
      "        [-1.2941e-06,  3.8824e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-8.8785e-06, -2.5883e-06,  0.0000e+00,  0.0000e+00])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-4.5013e-05, -2.6559e-05,  0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-3.0756e-05])\n",
      "**********\n",
      "Epoch 7/10, Loss: 2.3648283331567654e-10\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2887,  0.0842, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-7.2268e-07,  2.1680e-06],\n",
      "        [-2.1068e-07,  6.3204e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-1.4454e-06, -4.2136e-07,  0.0000e+00,  0.0000e+00])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-7.3277e-06, -4.3236e-06,  0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-5.0068e-06])\n",
      "**********\n",
      "Epoch 8/10, Loss: 6.266986929404084e-12\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2887,  0.0842, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-1.0324e-07,  3.0972e-07],\n",
      "        [-3.0097e-08,  9.0292e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-2.0648e-07, -6.0195e-08,  0.0000e+00,  0.0000e+00])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-1.0468e-06, -6.1766e-07,  0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-7.1526e-07])\n",
      "**********\n",
      "Epoch 9/10, Loss: 1.2789769243681803e-13\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2887,  0.0842, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n",
      "**********\n",
      "Gradient of hidden.weight: tensor([[-1.7207e-08,  5.1620e-08],\n",
      "        [-5.0163e-09,  1.5049e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of hidden.bias: tensor([-3.4413e-08, -1.0033e-08,  0.0000e+00,  0.0000e+00])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.weight: tensor([[-1.7447e-07, -1.0294e-07,  0.0000e+00,  0.0000e+00]])\n",
      "**********\n",
      "**********\n",
      "Gradient of output.bias: tensor([-1.1921e-07])\n",
      "**********\n",
      "Epoch 10/10, Loss: 3.552713678800501e-15\n",
      "Updated hidden.weight: tensor([[ 0.4097, -0.5240],\n",
      "        [-0.1462, -0.4054],\n",
      "        [ 0.0841,  0.5874],\n",
      "        [-0.5229,  0.4426]])\n",
      "Updated hidden.bias: tensor([0.4728, 0.3285, 0.3401, 0.3606])\n",
      "Updated output.weight: tensor([[ 0.2887,  0.0842, -0.0540,  0.0874]])\n",
      "Updated output.bias: tensor([0.5048])\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network (1 hidden layer)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 4)  # Increased hidden layer size\n",
    "        self.output = nn.Linear(4, 1)  # Hidden layer (4) -> Output layer (1)\n",
    "        self.activation = nn.ReLU()    # ReLU activation function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_out = self.activation(self.hidden(x))  # Apply activation after first layer\n",
    "        output = self.output(hidden_out)              # Compute final output\n",
    "        return output\n",
    "\n",
    "# Create a model instance\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define a simple loss function (Mean Squared Error for regression)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Sample input (2D input features) and target\n",
    "x = torch.tensor([[0.5, -1.5]], dtype=torch.float32)  # Single data point with 2 features\n",
    "y_true = torch.tensor([[1.0]], dtype=torch.float32)   # Target value\n",
    "\n",
    "# Training loop to observe weight changes\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # **FEEDFORWARD: Compute predictions**\n",
    "    y_pred = model(x)  # Forward pass\n",
    "    \n",
    "    # **LOSS CALCULATION: Compute error**\n",
    "    loss = loss_function(y_pred, y_true)\n",
    "    \n",
    "    # **BACKPROPAGATION: Compute gradients**\n",
    "    optimizer.zero_grad()  # Reset gradients to zero\n",
    "    loss.backward()  # Compute gradients using chain rule (automatic differentiation)\n",
    "    # Print computed gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        print(\"*\"*10)\n",
    "        print(f\"Gradient of {name}:\", param.grad)\n",
    "        print(\"*\"*10)\n",
    "    # **UPDATE WEIGHTS: Gradient Descent step**\n",
    "    optimizer.step()  # Update weights based on gradients\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "    \n",
    "    # Print updated parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Updated {name}:\", param.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
